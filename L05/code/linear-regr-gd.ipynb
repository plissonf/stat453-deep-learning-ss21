{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 453: Intro to Deep Learning and Generative Models (Spring 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sebastian Raschka\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.2\n",
      "IPython version      : 7.20.0\n",
      "\n",
      "torch     : 1.9.0a0+d819a21\n",
      "pandas    : 1.2.2\n",
      "matplotlib: 3.3.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/adaline-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions. The derivative and training procedure are identical to Adaline though. You can compare the two notebooks (this one and `adaline-sgd.ipynb`) side by side as shown below to see the relationship:\n",
    "\n",
    "![](figures/adaline-vs-linreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.1-cp38-none-macosx_10_9_x86_64.whl (147.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 147.1 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/Users/fabienplisson/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed torch-1.10.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.942094</td>\n",
       "      <td>-0.835856</td>\n",
       "      <td>-22.324428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.222445</td>\n",
       "      <td>-0.403177</td>\n",
       "      <td>-52.121493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.112466</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-57.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.403459</td>\n",
       "      <td>-0.412272</td>\n",
       "      <td>-27.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>-0.499017</td>\n",
       "      <td>-9.804714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "995 -0.942094 -0.835856 -22.324428\n",
       "996  1.222445 -0.403177 -52.121493\n",
       "997 -0.112466 -1.688230 -57.043196\n",
       "998 -0.403459 -0.412272 -27.701833\n",
       "999  0.021351 -0.499017  -9.804714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/linreg-data.csv', index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['x1', 'x2']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['y'].values, dtype=torch.float)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent70 = int(shuffle_idx.size(0)*0.7)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent70]], X[shuffle_idx[percent70:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent70]], y[shuffle_idx[percent70:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        grad_loss_yhat = 2*(yhat - y)\n",
    "        \n",
    "        grad_yhat_weights = x\n",
    "        grad_yhat_bias = 1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat - y)**2)\n",
    "\n",
    "\n",
    "def train(model, x, y, num_epochs, learning_rate=0.01):\n",
    "    cost = []\n",
    "    \n",
    "    #### Shuffle epoch\n",
    "    #shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "    #x=x[shuffle_idx]\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        \n",
    "        #### Compute outputs ####\n",
    "        yhat = model.forward(x)\n",
    "\n",
    "        #### Compute gradients ####\n",
    "        negative_grad_w, negative_grad_b = model.backward(x, yhat, y)\n",
    "\n",
    "        #### Update weights ####\n",
    "        model.weights += learning_rate * negative_grad_w\n",
    "        model.bias += learning_rate * negative_grad_b\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x) # not that this is a bit wasteful here\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 1532.67603\n",
      "Epoch: 002 | MSE: 1312.39856\n",
      "Epoch: 003 | MSE: 1133.91797\n",
      "Epoch: 004 | MSE: 989.30286\n",
      "Epoch: 005 | MSE: 872.12592\n",
      "Epoch: 006 | MSE: 777.18097\n",
      "Epoch: 007 | MSE: 700.24915\n",
      "Epoch: 008 | MSE: 637.91241\n",
      "Epoch: 009 | MSE: 587.40167\n",
      "Epoch: 010 | MSE: 546.47284\n",
      "Epoch: 011 | MSE: 513.30811\n",
      "Epoch: 012 | MSE: 486.43430\n",
      "Epoch: 013 | MSE: 464.65799\n",
      "Epoch: 014 | MSE: 447.01224\n",
      "Epoch: 015 | MSE: 432.71332\n",
      "Epoch: 016 | MSE: 421.12634\n",
      "Epoch: 017 | MSE: 411.73697\n",
      "Epoch: 018 | MSE: 404.12827\n",
      "Epoch: 019 | MSE: 397.96249\n",
      "Epoch: 020 | MSE: 392.96603\n",
      "Epoch: 021 | MSE: 388.91708\n",
      "Epoch: 022 | MSE: 385.63583\n",
      "Epoch: 023 | MSE: 382.97684\n",
      "Epoch: 024 | MSE: 380.82202\n",
      "Epoch: 025 | MSE: 379.07571\n",
      "Epoch: 026 | MSE: 377.66052\n",
      "Epoch: 027 | MSE: 376.51367\n",
      "Epoch: 028 | MSE: 375.58420\n",
      "Epoch: 029 | MSE: 374.83102\n",
      "Epoch: 030 | MSE: 374.22058\n",
      "Epoch: 031 | MSE: 373.72586\n",
      "Epoch: 032 | MSE: 373.32489\n",
      "Epoch: 033 | MSE: 372.99994\n",
      "Epoch: 034 | MSE: 372.73657\n",
      "Epoch: 035 | MSE: 372.52313\n",
      "Epoch: 036 | MSE: 372.35016\n",
      "Epoch: 037 | MSE: 372.20999\n",
      "Epoch: 038 | MSE: 372.09637\n",
      "Epoch: 039 | MSE: 372.00427\n",
      "Epoch: 040 | MSE: 371.92963\n",
      "Epoch: 041 | MSE: 371.86914\n",
      "Epoch: 042 | MSE: 371.82010\n",
      "Epoch: 043 | MSE: 371.78036\n",
      "Epoch: 044 | MSE: 371.74814\n",
      "Epoch: 045 | MSE: 371.72202\n",
      "Epoch: 046 | MSE: 371.70090\n",
      "Epoch: 047 | MSE: 371.68372\n",
      "Epoch: 048 | MSE: 371.66983\n",
      "Epoch: 049 | MSE: 371.65854\n",
      "Epoch: 050 | MSE: 371.64941\n",
      "Epoch: 051 | MSE: 371.64206\n",
      "Epoch: 052 | MSE: 371.63602\n",
      "Epoch: 053 | MSE: 371.63116\n",
      "Epoch: 054 | MSE: 371.62723\n",
      "Epoch: 055 | MSE: 371.62402\n",
      "Epoch: 056 | MSE: 371.62146\n",
      "Epoch: 057 | MSE: 371.61929\n",
      "Epoch: 058 | MSE: 371.61765\n",
      "Epoch: 059 | MSE: 371.61621\n",
      "Epoch: 060 | MSE: 371.61511\n",
      "Epoch: 061 | MSE: 371.61423\n",
      "Epoch: 062 | MSE: 371.61349\n",
      "Epoch: 063 | MSE: 371.61292\n",
      "Epoch: 064 | MSE: 371.61240\n",
      "Epoch: 065 | MSE: 371.61200\n",
      "Epoch: 066 | MSE: 371.61169\n",
      "Epoch: 067 | MSE: 371.61145\n",
      "Epoch: 068 | MSE: 371.61124\n",
      "Epoch: 069 | MSE: 371.61108\n",
      "Epoch: 070 | MSE: 371.61093\n",
      "Epoch: 071 | MSE: 371.61081\n",
      "Epoch: 072 | MSE: 371.61072\n",
      "Epoch: 073 | MSE: 371.61066\n",
      "Epoch: 074 | MSE: 371.61060\n",
      "Epoch: 075 | MSE: 371.61057\n",
      "Epoch: 076 | MSE: 371.61053\n",
      "Epoch: 077 | MSE: 371.61050\n",
      "Epoch: 078 | MSE: 371.61047\n",
      "Epoch: 079 | MSE: 371.61041\n",
      "Epoch: 080 | MSE: 371.61041\n",
      "Epoch: 081 | MSE: 371.61041\n",
      "Epoch: 082 | MSE: 371.61041\n",
      "Epoch: 083 | MSE: 371.61041\n",
      "Epoch: 084 | MSE: 371.61041\n",
      "Epoch: 085 | MSE: 371.61035\n",
      "Epoch: 086 | MSE: 371.61035\n",
      "Epoch: 087 | MSE: 371.61038\n",
      "Epoch: 088 | MSE: 371.61035\n",
      "Epoch: 089 | MSE: 371.61032\n",
      "Epoch: 090 | MSE: 371.61032\n",
      "Epoch: 091 | MSE: 371.61035\n",
      "Epoch: 092 | MSE: 371.61035\n",
      "Epoch: 093 | MSE: 371.61032\n",
      "Epoch: 094 | MSE: 371.61032\n",
      "Epoch: 095 | MSE: 371.61035\n",
      "Epoch: 096 | MSE: 371.61035\n",
      "Epoch: 097 | MSE: 371.61032\n",
      "Epoch: 098 | MSE: 371.61035\n",
      "Epoch: 099 | MSE: 371.61035\n",
      "Epoch: 100 | MSE: 371.61035\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train, \n",
    "             num_epochs=100, \n",
    "             learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 371.61035\n",
      "Test MSE: 406.88412\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights tensor([[ 0.3623],\n",
      "        [37.8790]])\n",
      "Bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical weights tensor([[ 0.3624],\n",
      "        [37.8801]])\n",
      "Analytical bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "def analytical_solution(x, y):\n",
    "    Xb = torch.cat( (torch.ones((x.size(0), 1)), x), dim=1)\n",
    "    w = torch.zeros(x.size(1))\n",
    "    z = torch.inverse(torch.matmul(Xb.t(), Xb))\n",
    "    params = torch.matmul(z, torch.matmul(Xb.t(), y))\n",
    "    b, w = torch.tensor([params[0]]), params[1:].view(x.size(1), 1)\n",
    "    return w, b\n",
    "\n",
    "w, b = analytical_solution(X_train, y_train)\n",
    "print('Analytical weights', w)\n",
    "print('Analytical bias', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Ungraded) HW Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the `train()` function such that the dataset is shuffled prior to each epoch. Do you see a difference -- Yes/No? Try to come up with an explanation for your observation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
